import streamlit as st
import pandas as pd
import numpy as np
import json
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns

# Set page configuration
st.set_page_config(
    page_title="HMM Market Regime Classifier",
    page_icon="ðŸ“ˆ",
    layout="wide"
)

# Load data
@st.cache_data
def load_dashboard_data():
    with open('dashboard_data.json', 'r') as f:
        return json.load(f)

# Load the preprocessed data
data = load_dashboard_data()

# Define state colors for consistency
STATE_COLORS = {
    0: {'color': '#1b9e77', 'bg': 'rgba(27, 158, 119, 0.3)', 'name': 'Bull Market'},
    1: {'color': '#d95f02', 'bg': 'rgba(217, 95, 2, 0.3)', 'name': 'Mixed Market 1'},
    2: {'color': '#7570b3', 'bg': 'rgba(117, 112, 179, 0.3)', 'name': 'Mixed Market 2'},
    3: {'color': '#e7298a', 'bg': 'rgba(231, 41, 138, 0.3)', 'name': 'Mixed Market 3'},
    4: {'color': '#66a61e', 'bg': 'rgba(102, 166, 30, 0.3)', 'name': 'Bear Market'}
}

# Main app function
def main():
    st.title("Financial Market Regime Classification with HMM")
    st.markdown("An interactive dashboard showcasing Hidden Markov Model analysis of market regimes")
    
    # Sidebar for navigation
    st.sidebar.title("Navigation")
    section = st.sidebar.radio(
        "Go to",
        ["Overview", "State Analysis", "Time Series", "Performance", "About"]
    )
    
    # Load content based on selection
    if section == "Overview":
        display_overview()
    elif section == "State Analysis":
        display_state_analysis()
    elif section == "Time Series":
        display_time_series()
    elif section == "Performance":
        display_performance()
    elif section == "About":
        display_about()

def display_overview():
    st.header("Project Overview")
    st.write("""
    This project uses Hidden Markov Models to classify financial market regimes (bull vs bear markets).
    The model discovers hidden states that correspond to different market conditions based on price and volatility patterns.
    The structured emission matrix approach helps better separate market regimes by encoding domain knowledge into the model initialization.
    """)
    
    # Key metrics in columns
    metrics = data['metrics']
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Accuracy", f"{metrics['accuracy']:.2%}",)
    col2.metric("Precision", f"{metrics['precision']:.2%}", )
    col3.metric("Recall", f"{metrics['recall']:.2%}",)
    col4.metric("F1 Score", f"{metrics['f1_score']:.2%}",)
    
    # Model configuration
    st.subheader("Model Configuration")
    config_col1, config_col2 = st.columns(2)
    
    with config_col1:
        st.info("**Hidden States:** 5")
        st.info("**Observations:** 20")
        st.info("**Training Steps:** 60")
    
    with config_col2:
        st.info("**Discretization:** Equal Frequency")
        st.info("**Classification Threshold:** 0.4")
        st.info("**Main Feature:** SP500 High-Low Range")
    
    # Display confusion matrix
    st.subheader("Confusion Matrix")
    if data['confusion_matrix']:
        cm = np.array(data['confusion_matrix'])
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                  xticklabels=['Predicted Bear', 'Predicted Bull'],
                  yticklabels=['Actual Bear', 'Actual Bull'])
        plt.title('Confusion Matrix')
        st.pyplot(fig)

def display_state_analysis():
    st.header("State Interpretation")
    
    # Create state interpretation table
    state_data = []
    for state, info in data['state_interpretations'].items():
        # Determine state type based on bull ratio
        if float(info['bull_ratio']) > 0.65:
            state_type = "Sideways/Mixed Market (Bull Bias)"
        elif float(info['bull_ratio']) < 0.40:
            state_type = "Sideways/Mixed Market (Bear Bias)"
        else:
            state_type = "Sideways/Mixed Market"
        
        state_data.append({
            "State": int(state),
            "Type": state_type,
            "Bull Ratio": f"{float(info['bull_ratio']):.2f}",
            "Mean": f"{float(info['mean']):.2f}",
            "Std Dev": f"{float(info['std']):.2f}",
            "_bull_ratio_value": float(info['bull_ratio'])  # For sorting
        })
    
    state_df = pd.DataFrame(state_data)
    state_df = state_df.sort_values('State').drop('_bull_ratio_value', axis=1)
    
    # Display table with conditional formatting
    st.dataframe(state_df.style.background_gradient(
        subset=["Bull Ratio"], cmap="RdYlGn"), use_container_width=True)
    
    # Display transition matrix as heatmap
    st.subheader("State Transition Heatmap")
    transition_matrix = np.array(data['transition_matrix'])
    
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(transition_matrix, annot=True, cmap="YlGnBu", 
              xticklabels=[f"State {i}" for i in range(len(transition_matrix))],
              yticklabels=[f"State {i}" for i in range(len(transition_matrix))])
    plt.title("State Transition Probabilities")
    plt.xlabel("To State")
    plt.ylabel("From State")
    st.pyplot(fig)
    
    # State distribution pie chart
    st.subheader("State Distribution")
    
    # Count occurrences of each state
    states = np.array(data['states'])
    state_counts = {}
    for i in range(5):  # Assuming 5 states
        count = np.sum(states == i)
        state_counts[f"State {i} ({STATE_COLORS[i]['name']})"] = count
    
    fig = px.pie(
        values=list(state_counts.values()), 
        names=list(state_counts.keys()),
        title="Overall State Distribution",
        color_discrete_sequence=[STATE_COLORS[i]['color'] for i in range(5)]
    )
    st.plotly_chart(fig, use_container_width=True)

def display_time_series():
    st.header("Time Series Analysis")
    
    # Create DataFrame with time series data
    features = np.array(data['features'])
    returns = np.array(data['returns'])
    states = np.array(data['states'])
    actual_labels = np.array(data['actual_labels'])
    
    # Convert dates if available, otherwise use indices
    if data['dates']:
        dates = pd.to_datetime(data['dates'])
    else:
        dates = np.arange(len(features))
    
    df = pd.DataFrame({
        'Date': dates,
        'Feature': features,
        'Return': returns,
        'State': states,
        'Actual_Label': actual_labels
    })
    
    # Date range selector
    st.subheader("Select Date Range")
    col1, col2 = st.columns(2)
    
    if isinstance(df['Date'].iloc[0], pd.Timestamp):
        min_date = df['Date'].min().date()
        max_date = df['Date'].max().date()
        
        # Default to last 2 years if data range is large enough
        default_start = max(min_date, max_date - pd.Timedelta(days=730))
        
        start_date = col1.date_input("Start Date", default_start, min_value=min_date, max_value=max_date)
        end_date = col2.date_input("End Date", max_date, min_value=min_date, max_value=max_date)
        
        # Filter data by date range
        mask = (df['Date'] >= pd.Timestamp(start_date)) & (df['Date'] <= pd.Timestamp(end_date))
        filtered_df = df[mask]
    else:
        # If no dates, use a range slider
        min_idx = 0
        max_idx = len(df) - 1
        
        # Default to last 20% of data
        default_start = int(max_idx * 0.8)
        
        range_values = col1.slider("Select Range", min_idx, max_idx, (default_start, max_idx))
        filtered_df = df.iloc[range_values[0]:range_values[1]+1]
    
    # Plot feature/volatility with state coloring
    st.subheader("Feature and Market Regimes")
    
    # Create figure
    fig = go.Figure()
    
    # Add feature line
    fig.add_trace(go.Scatter(
        x=filtered_df['Date'],
        y=filtered_df['Feature'],
        mode='lines',
        name='High-Low Range',
        line=dict(color='black', width=1.5)
    ))
    
    # Add colored backgrounds for each state
    for state in range(5):  # Assuming 5 states
        # Find continuous segments
        mask = (filtered_df['State'] == state)
        if not any(mask):
            continue
            
        # Get indices where state changes
        mask_array = mask.values
        change_points = np.where(mask_array[:-1] != mask_array[1:])[0]
        segments = []
        
        if mask_array[0]:
            # First segment starts at beginning
            start_idx = 0
        else:
            start_idx = None
            
        for i in change_points:
            if mask_array[i]:  # True to False transition
                segments.append((start_idx, i))
                start_idx = None
            else:  # False to True transition
                start_idx = i + 1
                
        # Handle last segment
        if start_idx is not None:
            segments.append((start_idx, len(mask_array) - 1))
        
        # Add shapes for each segment
        for start, end in segments:
            fig.add_shape(
                type="rect",
                x0=filtered_df['Date'].iloc[start],
                x1=filtered_df['Date'].iloc[end],
                y0=filtered_df['Feature'].min() * 0.95,
                y1=filtered_df['Feature'].max() * 1.05,
                fillcolor=STATE_COLORS[state]['bg'],
                line=dict(width=0),
                layer="below"
            )
        
        # Add a legend entry
        fig.add_trace(go.Scatter(
            x=[None],
            y=[None],
            mode='markers',
            marker=dict(size=10, color=STATE_COLORS[state]['color']),
            name=f"State {state}: {STATE_COLORS[state]['name']}"
        ))
    
    # Update layout
    fig.update_layout(
        title="High-Low Range with Market Regime Classification",
        xaxis_title="Date",
        yaxis_title="High-Low Range",
        height=500,
        legend_title="Market Regimes",
        hovermode="x unified"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Show returns with actual and predicted labels
    st.subheader("Returns with Classification")
    
    fig = go.Figure()
    
    # Add returns line
    fig.add_trace(go.Scatter(
        x=filtered_df['Date'],
        y=filtered_df['Return'],
        mode='lines',
        name='Log Returns',
        line=dict(color='black', width=1)
    ))
    
    # Add horizontal line at zero
    fig.add_shape(
        type="line",
        x0=filtered_df['Date'].iloc[0],
        x1=filtered_df['Date'].iloc[-1],
        y0=0,
        y1=0,
        line=dict(color="gray", width=1, dash="dash")
    )
    
    # Add scatter points colored by prediction
    bull_mask = filtered_df['State'].apply(
        lambda x: data['state_interpretations'][str(x)]['bull_ratio'] > 0.5)
    
    fig.add_trace(go.Scatter(
        x=filtered_df.loc[bull_mask, 'Date'],
        y=filtered_df.loc[bull_mask, 'Return'],
        mode='markers',
        marker=dict(
            color='green',
            size=6,
            opacity=0.7
        ),
        name='Predicted Bull'
    ))
    
    fig.add_trace(go.Scatter(
        x=filtered_df.loc[~bull_mask, 'Date'],
        y=filtered_df.loc[~bull_mask, 'Return'],
        mode='markers',
        marker=dict(
            color='red',
            size=6,
            opacity=0.7
        ),
        name='Predicted Bear'
    ))
    
    fig.update_layout(
        title="Log Returns with Model Classifications",
        xaxis_title="Date",
        yaxis_title="Log Return",
        height=400,
        legend_title="Predicted Class",
        hovermode="x unified"
    )
    
    st.plotly_chart(fig, use_container_width=True)

def display_performance():
    st.header("Model Performance Analysis")
    
    # Hard-coded metrics for the improved model
    actual_metrics = {
        'accuracy': 0.6612,
        'precision': 0.7083,
        'recall': 0.7133,
        'f1_score': 0.7108
    }
    
    st.subheader("Classification Performance")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Accuracy", f"{actual_metrics['accuracy']:.2%}")
    col2.metric("Precision", f"{actual_metrics['precision']:.2%}")
    col3.metric("Recall", f"{actual_metrics['recall']:.2%}")
    col4.metric("F1 Score", f"{actual_metrics['f1_score']:.2%}")
    
    # Confusion Matrix
    st.subheader("Confusion Matrix")
    
    if data['confusion_matrix']:
        cm = np.array(data['confusion_matrix'])
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=['Predicted Bear', 'Predicted Bull'],
                   yticklabels=['Actual Bear', 'Actual Bull'])
        plt.title('Confusion Matrix')
        st.pyplot(fig)
    
    # Model comparison
    st.subheader("Model Comparison")
    
    comparison = pd.DataFrame({
        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],
        'Improved Model': [0.6612, 0.7083, 0.7133, 0.7108],
        'Previous Structured': [0.6190, 0.7492, 0.5221, 0.6154],
        'Baseline Model': [0.6599, 0.6845, 0.7739, 0.7265]
    })
    
    st.table(comparison)
    
    # Create a bar chart for model comparison
    comparison_melted = pd.melt(
        comparison, 
        id_vars=['Metric'], 
        var_name='Model', 
        value_name='Value'
    )
    
    fig = px.bar(
        comparison_melted, 
        x='Metric', 
        y='Value', 
        color='Model',
        barmode='group',
        title="Model Performance Comparison"
    )
    
    fig.update_layout(
        yaxis=dict(range=[0, 1]),
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Classification quality over time
    st.subheader("Classification Quality Over Time")
    
    # Create DataFrame with time series data
    features = np.array(data['features'])
    returns = np.array(data['returns'])
    states = np.array(data['states'])
    actual_labels = np.array(data['actual_labels'])
    
    # Convert dates if available, otherwise use indices
    if data['dates']:
        dates = pd.to_datetime(data['dates'])
    else:
        dates = np.arange(len(features))
    
    df = pd.DataFrame({
        'Date': dates,
        'Feature': features,
        'Return': returns,
        'State': states,
        'Actual_Label': actual_labels
    })
    
    # Calculate if prediction matches actual label
    bull_mask = df['State'].apply(
        lambda x: data['state_interpretations'][str(x)]['bull_ratio'] > 0.5)
    df['Predicted_Label'] = bull_mask.astype(int)
    df['Correct'] = (df['Predicted_Label'] == df['Actual_Label']).astype(int)
    
    # Resample by month if dates are available
    if isinstance(df['Date'].iloc[0], pd.Timestamp):
        monthly_accuracy = df.set_index('Date').resample('M')['Correct'].mean()
        
        fig = px.line(
            x=monthly_accuracy.index,
            y=monthly_accuracy.values,
            title="Monthly Classification Accuracy",
            labels={'x': 'Date', 'y': 'Accuracy'}
        )
        
        fig.update_layout(
            yaxis=dict(range=[0, 1]),
            height=400
        )
        
        # Add a baseline at 0.5 (random guessing)
        fig.add_shape(
            type="line",
            x0=monthly_accuracy.index.min(),
            x1=monthly_accuracy.index.max(),
            y0=0.5,
            y1=0.5,
            line=dict(color="red", width=1, dash="dash")
        )
        
        st.plotly_chart(fig, use_container_width=True)


def display_about():
    st.header("About This Project")
    
    st.markdown("""
    ### Hidden Markov Model for Market Regime Classification
    
    This project applies Hidden Markov Models to financial market data to identify distinct market regimes (bull and bear markets). The key innovation is the use of a structured emission matrix that explicitly models different market conditions, providing better separation between regimes.
    
    ### Key Features
    
    - **5 Hidden States**: The model discovers 5 distinct states that correspond to different market conditions
    - **Structured Emission Matrix**: Initial parameters are designed to encode domain knowledge about market regimes
    - **Volatility Focus**: Uses the high-low range as the primary feature, emphasizing volatility as a key indicator
    - **Optimized Threshold**: Uses a 0.4 classification threshold to better balance precision and recall
    
    ### Model Implementation
    
    The model is implemented using PyTorch and includes:
    - Baum-Welch algorithm for parameter learning
    - Viterbi algorithm for state sequence inference
    - Custom evaluation methods for assessing model performance
    
    ### Future Work
    
    Potential improvements include:
    - Additional features for better regime identification
    - Time-varying transition probabilities
    - Integration with trading strategies
    - Hybrid models combining HMM with supervised learning
    """)

if __name__ == "__main__":
    main()